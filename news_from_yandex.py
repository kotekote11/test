import os
import json
import logging
import asyncio
import random
import requests
from aiohttp import ClientSession
from bs4 import BeautifulSoup

# –£—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏ API Telegram
API_TOKEN = os.getenv("API_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")
SENT_LIST_FILE = 'dump.json'

# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞
KEYWORDS = [
    "–æ—Ç–∫—Ä—ã—Ç–∏–µ —Ñ–æ–Ω—Ç–∞–Ω–æ–≤ 2025",
    "–æ—Ç–∫—Ä—ã—Ç–∏–µ —Ñ–æ–Ω—Ç–∞–Ω–æ–≤ 2026",
    "–æ—Ç–∫—Ä—ã—Ç–∏–µ —Å–≤–µ—Ç–æ–º—É–∑—ã–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–æ–Ω—Ç–∞–Ω–∞ 2025",
]

# –û–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –∏ –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º—ã–µ —Å–ª–æ–≤–∞
MUST_HAVE_WORDS = {"—Ñ–æ–Ω—Ç–∞–Ω", "—Ñ–æ–Ω—Ç–∞–Ω–æ–≤", "—Ñ–æ–Ω—Ç–∞–Ω–∞"}
IGNORE_WORDS = {"–ü–µ—Ç–µ—Ä–≥–æ—Ñ", "–Ω–µ—Ñ—Ç—å", "–Ω–µ–¥—Ä", "–º–µ—Å—Ç–æ—Ä–æ–∂–¥–µ–Ω–∏–µ"}
IGNORE_SITES = {"instagram", "livejournal", "fontanka", "avito"}

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ä–∞–Ω–µ–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
def load_sent_list():
    if os.path.exists(SENT_LIST_FILE):
        with open(SENT_LIST_FILE, 'r', encoding='utf-8') as file:
            return json.load(file)
    return []

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å—Å—ã–ª–æ–∫
def save_sent_list(sent_list):
    with open(SENT_LIST_FILE, 'w', encoding='utf-8') as file:
        json.dump(sent_list, file)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram
async def send_message(session, message):
    url = f"https://api.telegram.org/bot{API_TOKEN}/sendMessage"
    payload = {
        'chat_id': CHANNEL_ID,
        'text': message,
        'parse_mode': 'Markdown'  # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
    }
    async with session.post(url, json=payload) as response:
        if response.status == 200:
            logging.info('–°–æ–æ–±—â–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ.')
        else:
            logging.error(f'–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {response.status} - {await response.text()}')

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ URL
def clean_url_yandex(url):
    return url.split('?')[0]

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞–ª–∏—á–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Å–ª–æ–≤
def contains_must_have_words(title):
    return any(word in title.lower() for word in MUST_HAVE_WORDS)

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ Yandex
async def search_yandex(session, keyword):
    query = f'https://yandex.ru/search/?text={keyword}&within=77'
    user_agents = [
        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',
        'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',
        'Mozilla/5.0 (Macintosh; Intel Mac OS X 13_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.1 Safari/605.1.15'
    ]
    headers = {'User-Agent': random.choice(user_agents)}
    logging.debug(f'–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º Yandex –ø–æ –∞–¥—Ä–µ—Å—É: {query} —Å –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏: {headers}')
    async with session.get(query, headers=headers) as response:
        if response.status != 200:
            logging.error(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Yandex: {response.status} –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: {query}')
            return []
        logging.debug(f'–ü–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –æ—Ç Yandex: {response.status}')
        soup = BeautifulSoup(await response.text(), 'html.parser')
        results = []

        for item in soup.find_all('h2'):
            parent_link = item.find_parent('a')
            if parent_link and 'href' in parent_link.attrs:

                link = clean_url_yandex(parent_link['href'])
                title = item.get_text()
                logging.debug(f'–ù–∞–π–¥–µ–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫: {title} —Å —Å—Å—ã–ª–∫–æ–π: {link}')
                if contains_must_have_words(title):
                    results.append((title, link))
        logging.info(f'–ù–∞–π–¥–µ–Ω–æ {len(results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è {keyword} –≤ Yandex.')
        return results

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–æ–≤–æ—Å—Ç–µ–π
async def check_news(sem, sent_set):
    async with ClientSession() as session:
        for keyword in KEYWORDS:
            async with sem:
                logging.info(f'–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è: {keyword}')
                # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–≤–æ—Å—Ç–∏ –∏–∑ Yandex
                news_from_yandex = await search_yandex(session, keyword)

                for title, link in news_from_yandex:
                    if any(ignore in title for ignore in IGNORE_WORDS) or any(ignore in link for ignore in IGNORE_SITES):
                        continue
                    if link not in sent_set:
                        sent_set.add(link)
                        message_text = f"{title}\n{link}\n‚õ≤@MonitoringFontanüì∞#–§–æ–Ω—Ç–∞–Ω"
                        await send_message(session, message_text)

                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                save_sent_list(list(sent_set))
                await asyncio.sleep(random.randint(5, 15))

# –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
async def main():
    sem = asyncio.Semaphore(5)  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    sent_set = set(load_sent_list())  # –ó–∞–≥—Ä—É–∂–∞–µ–º —É–∂–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏

    while True:
        await check_news(sem, sent_set)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
        await asyncio.sleep(1111)  # –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø—Ä–æ–≤–µ—Ä–∫–∞–º–∏ (21 –º–∏–Ω—É—Ç–∞)

if __name__ == '__main__':
    asyncio.run(main())  # –ó–∞–ø—É—Å–∫–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é
