import os
import json
import logging
import asyncio
import random
import requests
from aiohttp import ClientSession
from bs4 import BeautifulSoup

# –ó–∞–¥–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è —Ç–æ–∫–µ–Ω–æ–≤ –∏ –¥—Ä—É–≥–∏—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
API_TOKEN = os.getenv("API_TOKEN")
CHANNEL_ID = os.getenv("CHANNEL_ID")
SENT_LIST_FILE = 'dump.json'

KEYWORDS = [
    "–æ—Ç–∫—Ä—ã—Ç–∏–µ —Ñ–æ–Ω—Ç–∞–Ω–æ–≤ 2025",
    "–æ—Ç–∫—Ä—ã—Ç–∏–µ —Ñ–æ–Ω—Ç–∞–Ω–æ–≤ 2026",
    "–æ—Ç–∫—Ä—ã—Ç–∏–µ —Å–≤–µ—Ç–æ–º—É–∑—ã–∫–∞–ª—å–Ω–æ–≥–æ —Ñ–æ–Ω—Ç–∞–Ω–∞ 2025",
]

IGNORE_WORDS = {"–ü–µ—Ç–µ—Ä–≥–æ—Ñ", "–Ω–µ—Ñ—Ç—å", "–Ω–µ–¥—Ä", "–º–µ—Å—Ç–æ—Ä–æ–∂–¥–µ–Ω–∏–µ"}
IGNORE_SITES = {"instagram", "livejournal", "fontanka"}

logging.basicConfig(level=logging.DEBUG)

# –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–∞–Ω–µ–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
def load_sent_list():
    if os.path.exists(SENT_LIST_FILE):
        with open(SENT_LIST_FILE, 'r') as file:
            return json.load(file)
    return []

# –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
def save_sent_list(sent_list):
    with open(SENT_LIST_FILE, 'w') as file:
        json.dump(sent_list, file)

# –û—á–∏—Å—Ç–∫–∞ URL
def clean_url(url):
    url = url[len('/url?q='):]
    url = url.split('&sa=U&ved')[0]
    return url

# –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Telegram
async def send_message(session, message_text):
    url = f'https://api.telegram.org/bot{API_TOKEN}/sendMessage'
    payload = {
        'chat_id': CHANNEL_ID,
        'text': message_text,
        'parse_mode': 'Markdown'
    }
    async with session.post(url, json=payload) as response:
        if response.status == 200:
            logging.info('–°–æ–æ–±—â–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ.')
        else:
            logging.error('–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è.')

# –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ Google
async def search_google(session, keyword):
    query = f'https://www.google.ru/search?q={keyword}&hl=ru&tbs=qdr:d'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'
    }
    async with session.get(query, headers=headers) as response:
        if response.status != 200:
            logging.error(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Google: {response.status}')
            return []
        soup = BeautifulSoup(await response.text(), 'html.parser')
        return [(item.get_text(), clean_url(item.find_parent('a')['href']))
                for item in soup.find_all('h3') if item.find_parent('a')]

# –ü–æ–∏—Å–∫ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ Yandex
async def search_yandex(session, keyword):
    query = f'https://yandex.ru/search/?text={keyword}&within=77'
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/87.0.4280.88 Safari/537.36'
    }
    async with session.get(query, headers=headers) as response:
        if response.status != 200:
            logging.error(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ Yandex: {response.status}')
            return []
        soup = BeautifulSoup(await response.text(), 'html.parser')
        results = []
        
        for item in soup.find_all('h2'):
            parent_link = item.find_parent('a')
            if parent_link and 'href' in parent_link.attrs:
                link = clean_url(parent_link['href'])
                results.append((item.get_text(), link))
        
        return results

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π
async def check_news(sem, sent_list):
    async with ClientSession() as session:
        for keyword in KEYWORDS:
            async with sem:
                logging.info(f'–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è: {keyword}')

                news_from_google = await search_google(session, keyword)
                news_from_yandex = await search_yandex(session, keyword)
                
                all_news = news_from_google + news_from_yandex

                for title, link in all_news:
                    if any(ignore in title for ignore in IGNORE_WORDS) or any(ignore in link for ignore in IGNORE_SITES):
                        continue

                    if link not in sent_list:
                        sent_list.append(link)
                        message_text = f"{title}\n{link}\n‚õ≤@MonitoringFontanüì∞#–§–æ–Ω—Ç–∞–Ω"
                        await send_message(session, message_text)

                        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ —Å—Å—ã–ª–∫–∏ –∫–∞–∂–¥—ã–µ 90 —Å–æ–æ–±—â–µ–Ω–∏–π
                        if len(sent_list) % 90 == 0:
                            save_sent_list(sent_list)

                # –°–ª—É—á–∞–π–Ω–∞—è –ø–∞—É–∑–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                await asyncio.sleep(random.randint(5, 15))

async def main():
    sem = asyncio.Semaphore(5)  # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    sent_list = load_sent_list()

    while True:
        await check_news(sem, sent_list)
        save_sent_list(sent_list)
        await asyncio.sleep(300)  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç

if __name__ == '__main__':
    asyncio.run(main())
